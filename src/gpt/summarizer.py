import openai
from datetime import datetime
import os
from dotenv import load_dotenv
import json
from typing import Optional, Dict

class GPTSummarizer:
    """GPT ê¸°ë°˜ í…ìŠ¤íŠ¸ ìš”ì•½ í´ë˜ìŠ¤"""
    
    def __init__(self, settings):
        """
        GPT ìš”ì•½ê¸° ì´ˆê¸°í™”
        
        Args:
            settings (dict): GPT ì„¤ì •
        """
        self.settings = settings
        self.model = settings['gpt']['model']
        self.temperature = settings['gpt']['temperature']
        self.max_tokens = settings['gpt']['max_tokens']
        
        # OpenAI API í‚¤ ë¡œë“œ
        load_dotenv()
        self.client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # Enhanced Analyzer ì´ˆê¸°í™”
        try:
            from .enhanced_analyzer import EnhancedInterviewAnalyzer
            self.enhanced_analyzer = EnhancedInterviewAnalyzer(settings)
            print("[GPTSummarizer] Enhanced Analyzer ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError as e:
            print(f"[GPTSummarizer] Enhanced Analyzer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.enhanced_analyzer = None
        
    def summarize(self, text):
        """
        í…ìŠ¤íŠ¸ ìš”ì•½ ìˆ˜í–‰
        
        Args:
            text (str): ìš”ì•½í•  í…ìŠ¤íŠ¸
            
        Returns:
            dict: ìš”ì•½ ê²°ê³¼
        """
        if not text.strip():
            print('[GPTSummarizer] ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŒ')
            return {}
        
        try:
            print('[GPTSummarizer] OpenAI API í˜¸ì¶œ ì‹œì‘')
            # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‚¬ìš©ì ì œì•ˆì— ë”°ë¼ ê°œì„ )
            prompt = f"""ë‹¤ìŒ í›„ë³´ì í”„ë¡œí•„ì„ ì•„ë˜ í•­ëª©ì— ì¤‘ì ì„ ë‘ì–´ ìš”ì•½í•´ ì£¼ì„¸ìš”:

{text}

ìš”ì•½ ì¤‘ì  ì‚¬í•­:
1. ê¸°ìˆ ì  HR ì „ë¬¸ì„±
2. ì „ëµì  ë° ë¦¬ë”ì‹­ ìì§ˆ
3. ì‚°ì—…ì— ëŒ€í•œ ê´€ì‹¬ê³¼ ì¥ê¸°ì ì¸ ë™ê¸°
4. ë¬¸í™” ì í•©ì„± ë° í˜‘ì—… ìŠ¤íƒ€ì¼

ë‹¨ìˆœí•œ ì—…ë¬´ ë‚˜ì—´ì„ í”¼í•˜ê³ , ê²½ë ¥ ì´ë™ê³¼ ì§ë¬´ì— ëŒ€í•œ ê´€ì‹¬ ì´ë©´ì— ìˆëŠ” *ì´ìœ *ë¥¼ íŒŒì•…í•´ ì£¼ì„¸ìš”."""

            # GPT API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ìš© ê´€ë¦¬ìë¥¼ ìœ„í•´ í›„ë³´ì í”„ë¡œí•„ì— ëŒ€í•œ í†µì°°ë ¥ ìˆê³  ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ HR ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            print('[GPTSummarizer] OpenAI API í˜¸ì¶œ ì„±ê³µ')
            
            # ì‘ë‹µ íŒŒì‹±
            summary_text = response.choices[0].message.content
            
            # ê²°ê³¼ êµ¬ì¡°í™”
            result = {
                'timestamp': datetime.now().isoformat(),
                'text_length': len(text),
                'summary': summary_text
            }
            
            # ì£¼ìš” í¬ì¸íŠ¸ì™€ í‚¤ì›Œë“œ ì¶”ì¶œ
            lines = summary_text.split('\n')
            main_points = []
            keywords = []
            
            for line in lines:
                line = line.strip()
                if line.startswith('- '):
                    main_points.append(line[2:])
                elif line.startswith('í‚¤ì›Œë“œ:'):
                    keywords = [k.strip() for k in line[6:].split(',')]
                    
            result['main_points'] = main_points
            result['keywords'] = keywords
            
            return result
            
        except Exception as e:
            print(f'[GPTSummarizer] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}')
            # API í‚¤ ì˜¤ë¥˜ ë“± ì˜ˆì™¸ ë°œìƒ ì‹œ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
            return {'summary': f'ìš”ì•½ ì‹¤íŒ¨: OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ ì ê²€í•˜ì„¸ìš”.\nì—ëŸ¬: {str(e)}'}
            
    def set_model(self, model):
        """GPT ëª¨ë¸ ì„¤ì •"""
        self.model = model
        
    def set_temperature(self, temperature):
        """ìƒì„± ì˜¨ë„ ì„¤ì •"""
        self.temperature = temperature
        
    def set_max_tokens(self, max_tokens):
        """ìµœëŒ€ í† í° ìˆ˜ ì„¤ì •"""
        self.max_tokens = max_tokens 

    def analyze_interview_and_get_summary(self, interview_text: str, template: Optional[Dict] = None) -> Dict:
        """
        í–¥ìƒëœ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸í„°ë·°ë¥¼ ë¶„ì„í•˜ê³ , ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ í¬í•¨í•œ ì „ì²´ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
        """
        if not self.enhanced_analyzer:
            print("[GPTSummarizer] Enhanced Analyzerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìš”ì•½ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            return self.summarize(interview_text)

        if template is None:
            template = {}

        try:
            print("[GPTSummarizer] Enhanced Analyzerë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì‹œì‘...")
            
            # Enhanced Analyzerì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ
            analysis_result = self.analyze_complete_interview(
                interview_script=interview_text,
                template=template,
                screening_data={}  # ì´ˆê¸° ìŠ¤í¬ë¦¬ë‹ ë°ì´í„°ëŠ” ë¹„ì–´ìˆìŒ
            )
            
            print("[GPTSummarizer] ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì™„ë£Œ.")
            return analysis_result

        except Exception as e:
            print(f"[GPTSummarizer] ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
            return self.summarize(interview_text)

    def summarize_incremental(self, incremental_prompt):
        """
        ì¦ë¶„ ìš”ì•½: ì‚¬ìš©ì ì»¤ìŠ¤í…€ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ìŠ¤í¬ë¦¬ë‹ ë…¸íŠ¸ ìƒì„±
        (í–¥í›„ ì´ ê¸°ëŠ¥ë„ Enhanced Analyzerë¡œ í†µí•© ê³ ë ¤)
        """
        try:
            # ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            lines = incremental_prompt.split('\n')
            new_text = ""
            for line in lines:
                if line.startswith('ìƒˆë¡œ ì¶”ê°€ëœ ë‚´ìš©:'):
                    new_text = '\n'.join(lines[lines.index(line)+1:])
                    break
            
            if not new_text.strip():
                return {"summary": "ìƒˆë¡œìš´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", "key_points": []}
            
            # ì»¤ìŠ¤í…€ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸
            custom_prompt = f"""
The following is newly mentioned content from an interview:

{new_text}

ğŸ“˜ **Please organize according to Screening Note Summary Guideline v2.0:**

**ğŸ¯ Select only relevant categories from the 9 core categories:**
1. **Work Experience**: Total years of experience, job titles, company names, relevant industry
2. **Technical Skills**: Systems, platforms, tools, certifications, real-world usage
3. **Project/Achievements**: Specific projects led/participated in, problems solved, outcomes achieved
4. **Industry Expertise**: Industry or product domain familiarity
5. **Global/Cultural Exposure**: Cross-country/regional collaboration, Korean or multinational team experience
6. **Job Motivation/Fit**: Interest in company/position, career alignment
7. **Relocation/Work Mode**: Current location, relocation willingness, onsite/remote preference
8. **Availability**: Current employment status, possible start date
9. **Compensation**: Previous compensation, salary expectations, bonus information

**ğŸ“ Few-Shot Learning Examples:**

**Example 1:**
Input: "I have been working at Johnson & Johnson for 13 years in payroll management and HR systems."
Output: {{"category": "Work Experience", "note": "13+ years of payroll management and HR systems experience at Johnson & Johnson."}}

**Example 2:**
Input: "I'm experienced with SAP SuccessFactors, Workday, and I have certifications in Project Management."
Output: {{"category": "Technical Skills", "note": "Hands-on with SAP SuccessFactors and Workday; certified in Project Management."}}

**Example 3:**
Input: "I led a major integration project that reduced processing time by 30% and solved data mapping issues."
Output: {{"category": "Project/Achievements", "note": "Led integration project reducing processing time by 30% and resolving data mapping issues."}}

**Example 4:**
Input: "I work with teams from LATAM, EMEA, and APAC. I'm comfortable with Korean leadership."
Output: {{"category": "Global/Cultural Exposure", "note": "Collaborated with LATAM, EMEA, and APAC teams; comfortable working with Korean leadership."}}

**Example 5:**
Input: "My last salary was $53.26 per hour. I'm looking for around $120K base salary."
Output: {{"category": "Compensation", "note": "Last comp: $53.26/hour; targeting $120K base salary."}}

**ğŸ“‹ Sentence Construction Principles:**
- Be specific (avoid vague terms without context)
- Include numeric values whenever possible (years, salary, team size, etc.)
- Avoid repeating the same content
- Do not abbreviate key technical terms (e.g., always write "SAP SuccessFactors" in full)
- One sentence per key idea

**If the content is not important or not applicable, respond with "Not Applicable".**

Please respond in JSON format:
{{
    "category": "Category name (one of the 9 above, or 'Not Applicable')",
    "note": "One sentence summary following guidelines (empty string if not applicable)",
    "summary": "Complete screening note"
}}
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": """You are a professional Screening Note specialist trained on Screening Note Summary Guideline v2.0 for English interviews. 

Your expertise:
- Creating structured, specific, and numeric-rich summaries in professional English
- Following exact sentence construction principles for enterprise recruitment
- Using recommended templates for consistency across all candidates
- Avoiding vague or abstract language in favor of concrete details
- Ensuring technical terms are accurate and complete (no abbreviations)
- Focusing on English interview context and North American business standards

You MUST follow the provided guidelines exactly and produce professional-quality screening notes that meet enterprise recruitment standards for English-speaking candidates."""},
                    {"role": "user", "content": custom_prompt}
                ],
                max_tokens=800,
                temperature=0.1  # ë§¤ìš° ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
            )
            
            result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                summary_json = json.loads(result)
                return summary_json
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                return {
                    "category": "Other",
                    "note": result,
                    "summary": result
                }
                
        except Exception as e:
            print(f"Custom guideline-based processing failed: {e}")
            return {
                "category": "Error",
                "note": f"Processing failed: {str(e)}",
                "summary": "Unable to process content."
            } 

    def generate_screening_note_with_speaker(self, conversation_text, interviewer_name):
        """í™”ì êµ¬ë¶„ì´ í¬í•¨ëœ ëŒ€í™”ì—ì„œ ìŠ¤í¬ë¦¬ë‹ ë…¸íŠ¸ ìƒì„±"""
        try:
            # í™”ì êµ¬ë¶„ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸
            speaker_aware_prompt = f"""
The following is a conversation from an English interview where "{interviewer_name}" is the interviewer:

{conversation_text}

ğŸ“˜ **Please organize according to Screening Note Summary Guideline v2.0:**

**ğŸš¨ CRITICAL INSTRUCTION: Only extract information from CANDIDATE responses. 
Interviewer statements provide context but should NEVER be included in the candidate's background/experience.**

**ğŸ¯ Select only relevant categories from the 9 core categories:**
1. **Work Experience**: Total years of experience, job titles, company names, relevant industry
2. **Technical Skills**: Systems, platforms, tools, certifications, real-world usage
3. **Project/Achievements**: Specific projects led/participated in, problems solved, outcomes achieved
4. **Industry Expertise**: Industry or product domain familiarity
5. **Global/Cultural Exposure**: Cross-country/regional collaboration, Korean or multinational team experience
6. **Job Motivation/Fit**: Interest in company/position, career alignment
7. **Relocation/Work Mode**: Current location, relocation willingness, onsite/remote preference
8. **Availability**: Current employment status, possible start date
9. **Compensation**: Previous compensation, salary expectations, bonus information

**ğŸ“ Few-Shot Learning Examples:**

**Example 1:**
Conversation:
{interviewer_name}: Tell me about your experience with payroll systems.
Candidate: I have been working at Johnson & Johnson for 13 years in payroll management and HR systems.

Output: {{"category": "Work Experience", "note": "13+ years of payroll management and HR systems experience at Johnson & Johnson."}}

**Example 2:**
Conversation:
{interviewer_name}: What tools have you worked with?
Candidate: I'm experienced with SAP SuccessFactors, Workday, and I have certifications in Project Management.

Output: {{"category": "Technical Skills", "note": "Hands-on with SAP SuccessFactors and Workday; certified in Project Management."}}

**ğŸ“‹ Sentence Construction Principles:**
- Extract ONLY from candidate responses, never from interviewer statements
- Be specific (avoid vague terms without context)
- Include numeric values whenever possible (years, salary, team size, etc.)
- Avoid repeating the same content
- Do not abbreviate key technical terms (e.g., always write "SAP SuccessFactors" in full)
- One sentence per key idea

**If the candidate content is not important or not applicable, respond with "Not Applicable".**

Please respond in JSON format:
{{
    "category": "Category name (one of the 9 above, or 'Not Applicable')",
    "note": "One sentence summary following guidelines (empty string if not applicable)",
    "summary": "Complete screening note"
}}
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": f"""You are a professional Screening Note specialist trained on Screening Note Summary Guideline v2.0 for English interviews with speaker differentiation.

Your expertise:
- Analyzing interview conversations between interviewer ({interviewer_name}) and candidate
- Creating structured summaries ONLY from candidate responses
- Completely ignoring interviewer statements when building candidate profiles
- Following exact sentence construction principles for enterprise recruitment
- Using recommended templates for consistency across all candidates
- Ensuring technical terms are accurate and complete (no abbreviations)
- Focusing on English interview context and North American business standards

CRITICAL RULE: You MUST distinguish between interviewer and candidate statements. NEVER include interviewer's background, experience, or statements as part of the candidate's profile."""},
                    {"role": "user", "content": speaker_aware_prompt}
                ],
                max_tokens=800,
                temperature=0.1  # ë§¤ìš° ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
            )
            
            result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                summary_json = json.loads(result)
                return summary_json
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                return {
                    "category": "Other",
                    "note": result,
                    "summary": result
                }
                
        except Exception as e:
            print(f"Speaker-aware screening note generation failed: {e}")
            return {
                "category": "Error",
                "note": f"Processing failed: {str(e)}",
                "summary": "Unable to process content."
            } 

    def categorize_interview_content(self, conversation_text, categories):
        """
        ì¸í„°ë·° ëŒ€í™” ë‚´ìš©ì„ ì‚¬ìš©ì ì •ì˜ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ ìš”ì•½
        (ì´ ê¸°ëŠ¥ì€ analyze_complete_interviewë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.)
        """
        print("[GPTSummarizer] 'categorize_interview_content'ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 'analyze_interview_and_get_summary'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # ì„ì‹œë¡œ í˜¸í™˜ì„±ì„ ìœ„í•´ Enhanced Analyzerë¥¼ í˜¸ì¶œí•˜ëŠ” ë¡œì§ìœ¼ë¡œ ì—°ê²°
        if self.enhanced_analyzer:
            # ì—¬ê¸°ì„œ templateì„ ë§Œë“¤ê±°ë‚˜ ì°¾ì•„ì•¼ í•˜ì§€ë§Œ, ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê°„ë‹¨íˆ ì²˜ë¦¬
            template = {"position": "CustomHR"} # ì¹´í…Œê³ ë¦¬ë¥¼ ë³´ê³  ì„ì‹œ ì¶”ì •
            analysis_result = self.analyze_interview_and_get_summary(conversation_text, template)
            if analysis_result.get("success"):
                return analysis_result.get("comprehensive_analysis", {}).get("detailed_analysis", {})
        
        return {"error": "This function is deprecated. Please use 'analyze_interview_and_get_summary'."}
            
    def _parse_category_text(self, text, categories):
        """í…ìŠ¤íŠ¸ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ë‚´ìš© íŒŒì‹± (JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ)"""
        result = {}
        lines = text.split('\n')
        current_category = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
            found_category = None
            for category in categories:
                if category.lower() in line.lower() and ':' in line:
                    found_category = category
                    break
                    
            if found_category:
                # ì´ì „ ì¹´í…Œê³ ë¦¬ ë‚´ìš© ì €ì¥
                if current_category and current_content:
                    result[current_category] = ' '.join(current_content).strip()
                    
                # ìƒˆ ì¹´í…Œê³ ë¦¬ ì‹œì‘
                current_category = found_category
                current_content = [line.split(':', 1)[1].strip() if ':' in line else '']
            elif current_category:
                current_content.append(line)
                
        # ë§ˆì§€ë§‰ ì¹´í…Œê³ ë¦¬ ë‚´ìš© ì €ì¥
        if current_category and current_content:
            result[current_category] = ' '.join(current_content).strip()
            
        return result
        
    def analyze_incremental_content(self, new_content, existing_categories):
        """
        ìƒˆë¡œ ì¶”ê°€ëœ ë‚´ìš©ë§Œ ë¶„ì„í•˜ì—¬ ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ì— ì¶”ê°€
        
        Args:
            new_content (str): ìƒˆë¡œ ì¶”ê°€ëœ ëŒ€í™” ë‚´ìš©
            existing_categories (list): ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ëª©ë¡
            
        Returns:
            dict: ìƒˆë¡œ ë¶„ì„ëœ ì¹´í…Œê³ ë¦¬ë³„ ë‚´ìš©
        """
        if not new_content.strip():
            return {}
        
        # Enhanced Analyzerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„
        template = {"position": "CustomHR"}  # ê¸°ë³¸ê°’ìœ¼ë¡œ CustomHR ì‚¬ìš©
        analysis_result = self.analyze_interview_and_get_summary(new_content, template)
        
        if analysis_result.get("success"):
            detailed_analysis = analysis_result.get("comprehensive_analysis", {}).get("detailed_analysis", {})
            
            # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            result = {}
            for category, analysis_data in detailed_analysis.items():
                if isinstance(analysis_data, dict) and "assessment" in analysis_data:
                    assessment_list = analysis_data["assessment"]
                    if isinstance(assessment_list, list):
                        result[category] = "\n".join(assessment_list)
                    else:
                        result[category] = str(assessment_list)
                else:
                    result[category] = str(analysis_data)
            
            return result
        
        return {}
    
    def analyze_complete_interview(self, interview_script: str, template: dict, screening_data: dict) -> dict:
        """Complete interview script analysis using Enhanced Analyzer"""
        
        if not self.enhanced_analyzer:
            return {
                "error": "Enhanced Analyzer not initialized.",
                "fallback_analysis": self._fallback_analysis(interview_script, template, screening_data)
            }
        
        try:
            print("[GPTSummarizer] ğŸš€ Enhanced Analyzerë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì‹œì‘...")
            print(f"[GPTSummarizer] ğŸ“„ ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(interview_script)}ì")
            
            # 1. Extract candidate profile
            print("[GPTSummarizer] ğŸ“Š Step 1: í›„ë³´ì í”„ë¡œí•„ ì¶”ì¶œ ì¤‘...")
            candidate_profile = self.enhanced_analyzer.extract_candidate_profile(interview_script, template)
            print(f"[GPTSummarizer] âœ… Step 1 ì™„ë£Œ: í›„ë³´ì '{candidate_profile.get('candidate_name', 'Unknown')}' í”„ë¡œí•„ ì¶”ì¶œë¨")
            
            # 2. Comprehensive interview analysis
            print("[GPTSummarizer] ğŸ” Step 2: ì¢…í•©ì  ì¸í„°ë·° ë¶„ì„ ì¤‘...")
            comprehensive_analysis = self.enhanced_analyzer.analyze_comprehensive_interview(
                interview_script, template, candidate_profile
            )
            print(f"[GPTSummarizer] âœ… Step 2 ì™„ë£Œ: {len(comprehensive_analysis.get('detailed_analysis', {}))}ê°œ ì¹´í…Œê³ ë¦¬ ë¶„ì„ë¨")
            
            # 3. Improve existing screening notes
            print("[GPTSummarizer] ğŸ“ Step 3: ìŠ¤í¬ë¦¬ë‹ ë…¸íŠ¸ ê°œì„  ì¤‘...")
            improved_screening = self.enhanced_analyzer.improve_screening_notes(
                screening_data, interview_script, template
            )
            print("[GPTSummarizer] âœ… Step 3 ì™„ë£Œ: ìŠ¤í¬ë¦¬ë‹ ë…¸íŠ¸ í’ˆì§ˆ ê°œì„ ë¨")
            
            # 4. Generate final report
            print("[GPTSummarizer] ğŸ“‹ Step 4: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
            final_report = self.enhanced_analyzer.generate_final_report(
                candidate_profile, comprehensive_analysis, improved_screening, interview_script, template
            )
            print(f"[GPTSummarizer] âœ… Step 4 ì™„ë£Œ: {len(final_report)}ì ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ë¨")
            
            print("[GPTSummarizer] ğŸ‰ ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì™„ë£Œ!")
            
            return {
                "success": True,
                "candidate_profile": candidate_profile,
                "comprehensive_analysis": comprehensive_analysis,
                "improved_screening": improved_screening,
                "final_report": final_report,
                "analysis_timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"[GPTSummarizer] âŒ ì „ì²´ ì¸í„°ë·° ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "error": f"Analysis failed: {str(e)}",
                "fallback_analysis": self._fallback_analysis(interview_script, template, screening_data)
            }
    
    def _fallback_analysis(self, interview_script: str, template: dict, screening_data: dict) -> dict:
        """Basic analysis when Enhanced Analyzer fails"""
        try:
            # Perform basic summary
            basic_summary = self.summarize(interview_script[:2000])  # Length limit
            
            return {
                "type": "basic_analysis",
                "summary": basic_summary.get('summary', 'Unable to perform basic analysis.'),
                "screening_summary": self._summarize_screening_data(screening_data),
                "recommendation": "Only basic analysis available as Enhanced Analyzer is not accessible."
            }
            
        except Exception as e:
            return {
                "type": "error",
                "message": f"Basic analysis also failed: {str(e)}"
            }
    
    def _summarize_screening_data(self, screening_data: dict) -> str:
        """Summarize screening data"""
        if not screening_data:
            return "No screening data available."
        
        summary_parts = []
        summary_parts.append("=== Screening Notes Summary ===")
        
        for category, content in screening_data.items():
            if content and content.strip():
                summary_parts.append(f"\nâ–¼ {category}")
                # Organize content by lines
                lines = content.strip().split('\n')
                for line in lines[:3]:  # Maximum 3 lines
                    if line.strip():
                        summary_parts.append(f"   â€¢ {line.strip()}")
        
        return '\n'.join(summary_parts)
    
    def quick_profile_extraction(self, interview_text: str) -> dict:
        """Quick candidate profile extraction (for immediate display in SummaryWidget)"""
        
        if self.enhanced_analyzer:
            try:
                return self.enhanced_analyzer.extract_candidate_profile(interview_text, {})
            except Exception as e:
                print(f"[GPTSummarizer] Quick profile extraction failed: {e}")
        
        # Fallback: simple regex extraction
        return self._basic_profile_extraction(interview_text)
    
    def _basic_profile_extraction(self, text: str) -> dict:
        """Basic profile extraction using regex"""
        
        # Attempt to extract name
        name_patterns = [
            r'(?:Hi,?\s+)?(?:I\'m|My name is|This is)\s+([A-Z][a-z]+)',
            r'Interviewer:\s*Hi\s+([A-Z][a-z]+)',
            r'^([A-Z][a-z]+):',  # Extract name from conversation format
        ]
        
        name = "Not specified"
        for pattern in name_patterns:
            match = re.search(pattern, text, re.MULTILINE)
            if match:
                name = match.group(1)
                break
        
        # Extract company
        company_match = re.search(r'(?:at|with|from)\s+([A-Z][a-zA-Z\s&]+(?:Inc|Corp|LLC|Company|Solutions|Logistics|Group))', text)
        company = company_match.group(1) if company_match else "Not specified"
        
        # Extract salary information
        salary_patterns = [
            r'\$(\d{1,3}(?:,\d{3})*(?:\.\d{2})?)',
            r'(\d{1,3}(?:,\d{3})*)\s*(?:k|K|thousand)',
            r'base salary of.*?\$?(\d{1,3}(?:,\d{3})*)'
        ]
        
        salary = "Not specified"
        for pattern in salary_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                salary = f"${match.group(1)}"
                break
        
        return {
            "candidate_name": name,
            "current_company": company,
            "salary_expectation": salary,
            "extraction_method": "basic_regex"
        }

    def quick_categorize_text(self, text: str, categories: list) -> dict:
        """
        í…ìŠ¤íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜ (Enhanced Analyzer ì—†ì´)
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            categories (list): ë¶„ë¥˜í•  ì¹´í…Œê³ ë¦¬ ëª©ë¡
            
        Returns:
            dict: ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ê²°ê³¼
        """
        if not text.strip():
            return {}
        
        try:
            print(f"[GPTSummarizer] âš¡ ë¹ ë¥¸ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì)")
            
            # ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            categories_str = ", ".join(categories)
            
            # ì˜ì–´ ì „ìš© ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
            quick_prompt = f"""Please categorize the following interview text into the most appropriate category based on the definitions below and provide a brief summary in ENGLISH ONLY.

**--- CATEGORY DEFINITIONS ---**

*   **`Expertise`**: Core professional skills, specific accomplishments, and direct job-related experiences. (e.g., "Managed payroll for 500 employees," "Developed a new sales pipeline.")
*   **`Industry/Product/Technical Familiarity`**: Knowledge of the specific industry, markets, products, or technologies. (e.g., "Familiar with the automotive sector," "Experience with SAP and Workday.")
*   **`Leadership/Cultural Fit`**: Leadership style, team collaboration, and adaptability to the work environment. (e.g., "Led a team of 5 engineers," "Comfortable in a fast-paced startup.")
*   **`Motivation/Reason for Interest`**: Why the candidate is seeking a new role and their interest in this specific company. (e.g., "Seeking more growth opportunities," "Attracted to the company's mission.")
*   **`Logistics`**: Practical details like salary, location, and availability. (e.g., "Looking for $120K base," "Can start in 2 weeks.")

**--- INTERVIEW TEXT ---**
{text}

**--- RESPONSE FORMAT (JSON) ---**
Response in JSON format (ALL TEXT MUST BE IN ENGLISH):
{{
    "Category_Name": {{
        "assessment": ["Summary point 1 in English", "Summary point 2 in English"]
    }}
}}

**--- CRITICAL REQUIREMENTS ---**
- **Adhere strictly to the category definitions above.**
- **ALL output text must be in English only.**
- **CAPTURE BOTH OBJECTIVE FACTS AND SUBJECTIVE EXPRESSIONS** (emotions, motivations, values, thoughts).
- **USE RESUME-STYLE BULLET POINTS**: Start directly with action verbs, NO SUBJECTS (he/she/candidate).
    - âœ… Good: "Manages HR operations for 700+ employees."
    - âœ… Good: "Expresses passion for the automotive industry."
    - âŒ Avoid: "He manages HR operations..."
- **IF NO CONCRETE INFORMATION EXISTS FOR A CATEGORY, SIMPLY SKIP THAT CATEGORY.**
- Use specific numbers when mentioned (e.g., "3-year" instead of "multi-year").
- Keep summaries concise and action-oriented.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",  # ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": "You are a professional interview content categorizer. You MUST respond ONLY in English. Analyze and categorize interview content accurately and concisely in English only."},
                    {"role": "user", "content": quick_prompt}
                ],
                temperature=0.1,
                max_tokens=800,
                response_format={ "type": "json_object" }
            )
            
            result = response.choices[0].message.content
            print(f"[GPTSummarizer] âœ… ë¹ ë¥¸ ë¶„ì„ ì™„ë£Œ (ì˜ì–´ ì „ìš©)")
            
            try:
                return json.loads(result)
            except json.JSONDecodeError:
                print(f"[GPTSummarizer] JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜")
                return {"Other": {"assessment": [f"Analysis error: {result[:100]}..."]}}
                
        except Exception as e:
            print(f"[GPTSummarizer] ë¹ ë¥¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"Other": {"assessment": [f"Analysis failed: {text[:100]}..."]}}